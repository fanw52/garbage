# StrucTexT

Structured text understanding on Visually Rich Documents (VRDs) is a crucial part of Document Intelligence. Due to the complexity
of content and layout in VRDs, structured text understanding has been a challenging task. Most existing studies decoupled this problem into two sub-tasks: entity labeling and entity linking, which require an entire understanding of the context of documents at
both token and segment levels. However, little work has been concerned with the solutions that efficiently extract the structured
data from different levels. This paper proposes a unified framework named StrucTexT, which is flexible and effective for handling both
sub-tasks. Specifically, based on the transformer, we introduce a segment-token aligned encoder to deal with the entity labeling
and entity linking tasks at different levels of granularity. Moreover, we design a novel pre-training strategy with three self-supervised
tasks to learn a richer representation. StrucTexT uses the existing Masked Visual Language Modeling task and the new Sentence Length Prediction and Paired Boxes Direction tasks to incorporate the multi-modal information across text, image, and layout. We evaluate our method for structured text understanding at segment-level and token-level and show it outperforms the state-of-the-art counterparts with significantly superior performance on the FUNSD,SROIE, and EPHOIE datasets

![image-20220109141535442](StrucText.assets/image-20220109141535442.png)

* Layout embedding
  * $L = Emb_ğ‘™ (ğ‘¥0,ğ‘¦0, ğ‘¥1,ğ‘¦1,ğ‘¤, â„)$
  * å¯¹äºæ²¡æœ‰å­—ç¬¦çº§åˆ«æˆ–è€…å•è¯çº§åˆ«æ ‡æ³¨çš„ï¼Œé‡‡ç”¨segment-levelçº§åˆ«æ ‡æ³¨ç»“æœä¼°è®¡å•è¯æˆ–å­—ç¬¦ä½ç½®
* Language token embedding
  * language token embedding
    * $T = Embğ‘¡ (S) + L$ 
    * $S = {[CLS], ğ‘_1^1, Â· Â· Â· , ğ‘_{ğ‘™_1}^1, Â· Â· Â· , ğ‘_1^n, Â· Â· Â· , ğ‘_{ğ‘™_ğ‘›}^ğ‘›, [SEP]} $
* Visual segment emebedding
  * $V = Emb_ğ‘£ (ROIAlign(CNN(ğ¼), ğ‘)) + L$
* Segment ID embedding:  
  * æ¯ä¸ªtext segment åˆ†é…å”¯ä¸€ä¸€ä¸ªid
* other embedding
  * position embedding
    * encodes the indexes from 1 to maximum sequence length
  * Segment embedding
    * denotes the modality for each feature

* é¢„è®­ç»ƒä»»åŠ¡

  * Masked Visual language model
    * ä¸¤ä¸ªè¾“å…¥æºï¼šå›¾åƒä¸æ–‡æœ¬ï¼ŒæŒ‰ä¸€å®šçš„æ¯”ä¾‹maskæ–‡æœ¬ä¸­éƒ¨åˆ†tokenï¼Œå¹¶é¢„æµ‹è¢«maskçš„tokenï¼Œå¯¹åº”çš„å›¾åƒåŒºåŸŸä¸åšmask,ç›®çš„æ˜¯å»ºç«‹å›¾åƒä¸æ–‡æœ¬ä¹‹é—´çš„å…³è”
  * å­—ç¬¦é•¿åº¦é¢„æµ‹
    * å¯¹å›¾åƒsegmentï¼ˆRoIï¼‰é¢„æµ‹è¯¥åŒºåŸŸçš„å•è¯é•¿åº¦

  * å­—æ®µæ–¹ä½é¢„æµ‹
    * é¢„æµ‹ä¸¤ä¸ªsegmentçš„æ–¹å‘å…³ç³»ã€8ç§ã€‘
    * æ ¹æ®ä¸¤ä¸ªsegmentçš„ç›¸å¯¹ä½ç½®å…³ç³»ï¼Œç¡®å®šå…·ä½“æ–¹å‘

