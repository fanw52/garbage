# 目标检测

### YOLO

**Note**

**yolo系列中正负样本分别是怎么选取的**

* yolov1这种anchor-free的方法中，则是通过确定目标所在的grid cell来确定正负样本，这种方法的缺陷在于不能解决密集型小样本的问题，因为每个cell最多预测两个目标，并且正样本取IoU重叠面积较大的那个

* 基于anchor的多尺度目标训练策略中，会根据ground truth与anchor box的IoU确定正负样本

**目标检测中都存在一些什么问题**

* 小目标检测
  * FPN、PAN结构多尺度预测
  * 数据增强，生成小目标数据
* 难区分样本
  * Focal loss
  * OHEM
* 目标遮挡问题【密集场景下】
  * https://blog.csdn.net/andyjkt/article/details/107849011
* 目标漏检
  * https://www.zhihu.com/question/372208101/answer/1081615554
  * 可以从如下几个角度考虑
    * 数据增强
      * 部分类别的样本呈现长尾分布，可进行针对性的增强，缓解长尾分部的情况
    * 改进网络结构
      * 目标尺寸的巨大变化；解决办法，FPN，multi-scaling training等策略
    * 改进损失函数
      * Class-balanced Focal Loss
      * OHEM
        * 先通过前向传播计算RoI的损失，然后对RoI进行NMS，再对抑制后的目标依据损失值排序，选择前N个样本作为困难样本进行反向传播
        * 正负样本的选择，当ROI和任意一个GT的IoU大于0.5则为正样本，ROI和所有的GT的IoU小于0.5时，则为负样本
      * 后处理
    * 其他
      * 基于active learning的思想，增加训练样本和迭代模型，其中会包含一些样本选择的策略，比如通过信息熵等或者距离等指标选出最不确定的样本
      * 半监督式的主动学习，挑选出预测结果较为明确的样本，将预测结果作为标签，可以结合第一个策略使用，先挑选不确定样本进行标注，随后数次迭代模型，再利用半监督式的主动学习扩展训练样本的数据量

**Yolov1**

* yolo系列的开山之作，解决了two-stage目标检测的效率问题
* CNN提取图像特征
* 不足之处：一个物体的中心点如果落在了某个格子内，那么这个格子就负责预测该物体，没有物体中心点落进来的格子不负责预测任何物体
* 回归损失函数通过中心点以及宽高的偏移量计算获得，AP的计算不一致

**Yolov2**

* Better: 
  * 多尺度图像训练【更高分辨率】
  * 利用先验信息，引入anchor box概念，提高召回率
  * 对预测目标的中心位置进行了约束，将预测中心限制在特定的grid内，解决训练初期不稳定的问题

* Faster: darknet19速度更快

* Stronger: 采用分层分类的方法，进行更多类别的对象识别

**Yolov3**

* 引入FPN结构，进行多尺度目标预测

* sigmoid替换softmax，进行多目标预测

* 由darknet19演变至darknet53，引入resnet中的shortcut结构
* 正负样本的选择

**Yolov4**

* CSPDarNet53，引入cspnet结构，降低计算量
* PAN+SPP
* DIoU loss/CIoU loss/GIoU loss
* 各种数据增强

* 目标检测主要分为一阶段和二阶段的算法。
* 一阶段算法主要是yolo系列，主要的目标是速度更快，准确率更高，同时要兼容不同硬件设备的使用，因此，会根据设备的要求提供参数量不同的多个模型。


**YOLOX**

* 从数据的角度主要存在如下问题：

  * 小目标
    * 数据增强，mosaic
  * 目标尺寸变化大
    * 数据增强，crop
  * 正负样本不均匀
    * 损失函数的角度，focal loss
    * 采样策略，ohem，根据loss筛选正样本
    * anchor的选择，label assignment，根据loss选择固定区域的topk个正样本，
    * 数据增强，mosaic,mixup等等
* 从应用的角度来说，可能存在如下问题：

  * 考虑设备的性能，采用大模型还是小模型
  * 是否应用在移动端，考虑是否是要用轻量化模型，是否需要蒸馏，量化
* 针对一些特殊的情况

  * 考虑是否使用额外的数据，比如红外
* 目前也会有一些使用transformer进行图片分类与图片识别的工作，但目前来看计算量较大，从应用的角度来说还不成熟。

### YOLO演变史

* faster rcnn系列的目标检测主要问题是速度慢，无法进行大规模，或者实时性的应用，YOLO系列通过更为简单的流程，计算量更小的模型，逐步地取代faster rcnn
* YOLOv1，开山之作，利用VGG编码输入图片，编码后的向量直接回归box和类别，将proposal的获取和回归合二为一。大大简化了检测流程，不足之处在于无法处理密集型目标，原因在于YOLOv1将目标中心所对应的网格作为唯一的正样本，对于临近的落在同一个网格内的其他目标，通过IoU指标确定哪个目标作为正样本，另外一个则被丢弃；每个网格最多预测两个box。这也直接导致了定位不准的现象，可以归结为正负样本选择不恰当。
* YOLOv2，对v1进行全方位的升级，包含三个关键词：better，faster，stronger。better意为指标更好：多尺度图片输入训练，引入anchor的概念，获取更多更合理的正负样本，改变了目标框的表示方法，使得目标中心固定在一个范围内，解决训练初期不稳定的问题；faster则是速度更快，提出darknet19；stronger表示可以进行更多类别的检测识别任务，这边主要采用分层分类的方法，将所有的类别划分为树结构，每一个类别的概率依据该类别的父节点到当前节点的路径的概率得到。
* YOLOv3，在模型结构上进行了改进，进一步提高了检测的准确率，将darknet19升级至darknet53，由于层数加深，引入resnet中的shortcut结构，解决梯度消失的问题。引入FPN结构，进行多尺寸预测，将softmax替换为sigmoid，进行多标签分类
* YOLOv4，在v3的基础上，集成了多种trick，网络结构上，用CSPDarkNet53替换DarkNet53，引入PAN、SPP等结构，PAN结构是FPN的升级版，SPP主要是是降低目标尺寸对检测结果的影响【实际实现会采用用多种尺度不同的kernel进行池化操作，并将结果加在一起】，backbone部分还包含一些例如dropblock，mish等。损失函数采用CIoU loss【相应的NMS变为DIoU NMS】，进行了多种数据增强：mosaic、mixup【像素加权叠加】、cutmix【覆盖叠加】。
* YOLOv5，与v4类似，集成了很多trick，不同的是，v5，在输入端的focus模块，沿xy轴对按一定的步长对图像进行拆分，好处在于降低运算量。使用了auto anchor，网络的深度和channel的宽度通过depth_multiple以及width_multiple控制。
* YOLOX，是anchor-free方法在YOLO中的进一步探索，直接回归检测目标的中心以及宽高，避免因anchor设置的不合理而带来的检测问题，同时也降低了检测的复杂度【anchor机制会引入非常多的样本】，将目标中心位置3x3的区域作为正样本区域，缓解正负样本不平衡问题，引入decouple head，强化模型性能；另外一个比较有意思的是simOTA：通过loss反映GT和anchor的匹配度，并为每一个GT选择固定区域若k个匹配的预测结果，有点类似于OHEM，不同的是，simOTA的k值会因为不同的GT而改变。

### two-stage目标检测

* Faster RCNN，二阶段目标检测的经典之作，第一阶段是一个二分类的检测回归任务，确定是否是物体；第二阶段是一个多分类的检测回归任务，结合RoI pooling，进行多类别的检测回归任务。
* Mask RCNN，沿用faster rcnn的思想，特征提取部分采用resnet-fpn结构，额外增加了一个mask预测分支，是一个像素级的预测任务，使用RoI Align替代RoI Pooling，解决特征图与原始图不对齐的问题。【特征图上的非整数点，利用周围整数网格的整数点双线性插值得到】

###  DETR

* 将transformer运用到目标检测领域，并且规避了anchor box，nms之类的算法，比较新颖。这个工作本身使用encode-decode模块生成固定的N个预测框，这里比较新颖的是利用匈牙利算法，匹配predict box和target
* 匈牙利算法：https://zhuanlan.zhihu.com/p/96229700

### 文字检测

* DBNet，基于语义分割的文字检测方法，引入可微分二值化模块，阈值动态可调，简化了模型的后处理流程，提高了模型的performance；优势：速度快，性能好，缺点：召回率相对较低【目前仍不是很理解为什么召回率低，EAST的召回率相对会高一些，但EAST的精准率相对较低】。
* PSENet，基于语义分割的文字检测方法，拟合并合并多个kernel，作为最终的检测结果，优点：表现好，缺点：速度慢，后处理复杂。
* EAST，一种anchor-free的回归方法，引入FPN结构，融合上采样的特征，回归到四条边的距离以及倾斜角，提出了lanms，认为临近的文本框高度相似，以文本框的置信度作为权重对高度重合的文本框加权融合，并结合nms输出检测结果。优点：速度快，表现好，流程简单高效；缺点：

### 文字识别

* CRNN+CTC，核心在CTC，解决标签不对齐的问题，通过计算所有可表示为目标序列的概率和来表示损失函数。
* Attention，将输入图片转化为隐向量，并利用注意力机制，对隐向量解码的方法。优点：是一种语言模型，可学习到字符之间的关联，缺点：存在attention drift的问题，对字符数较多的图像表现不好；中文字符较多，需要大量的数据建模字符之间的关联。

### backbone的选型

* Resnet-vd，resnet的变种，将pointwise convolution的步长从2调整到1，并引入pooling近似原先的操作。避免了pointwise convolution丢失信息的问题。
* CSPDarkNet53，引入CSPNet结构，避免重复信息，减少了计算量，起到模型加速的作用。
* MobileNet-v3，轻量级模型，使用了深度可分离卷积模块，保证了模型整体的计算量不会很大，同时通过逆残差结构，避免输入特征在降维的过程中丢失信息的问题，并引入SE模块强化模型特征提取能力，最终通过NAS的方法，获取最优模型结构。
* SENet，squeeze-excitate，整体是一种注意力机制，squeeze：global average pooling对输入特征做压缩，压缩后的特征使用全连接作exciate，得到的结果softmax归一化，作为注意力权重，作用于输入特征。

### 常见的问题

* 文字检测

  * 文字密集，行间距差异较大
  * dbnet长文本特殊的调整
  * 竖排文字
  * 模糊，字迹淡

* 文字识别

  * 形近字，生僻字识别
    * 合成包含形近字和生僻字的图片数据，涉及到字体，背景以及语料的选择
  * 损失函数
    * Focal ctc loss
    * center loss

* 目标检测

  * 除了常见的小目标，另外一个比较明显的就是目标覆盖重叠

* 版面分析

  * 1、判断文书模板；2、检测角点；3、摆正图片【摆正图片合理性判断】；4、区域匹配；5、文字识别；6、后处理
  * 难点：相同文书存在多个模板；角点遮挡；

* 证件识别

  * 与文书版面分析一致，反光图片识别效果不佳

* 关系抽取

  * 用户观点抽取：特殊处理标签，形如：pair<实体1，实体2>，表示前后两个实体存在关联，进而将关系抽取任务转变成序列标注任务，但这种建模方法只能建立两个相邻实体之间的关联，即两个关联实体之间不能存在其他实体。

  * 用户观点数据生成，基于远程监督的方法，该方法认为某个实体对存在某种关系，那么包含这个实体对的所有语料都能阐述这个关系

  * 以人为中心的关系抽取问题，采用TPLinker，解决重叠识别，重叠关系的抽取与识别问题。主要工作在于构造数据

    

  

### 利用bad case去优化模型的例子

* 文字检测	
  * 我们发现，文字检测模块对有少量180度旋转的图片检测效果不佳，因此，在数据增强的过程中以一定的概率对图片进行180度旋转，模拟这种检测不佳的场景。
  * 对于密集型表格图片，以前的算法会出现串行现象，我们采用基于语义分割方法的DBNet解决了这种串行的现象，这个模型将提出了可微分二值化模块，模型可以自适应地设置阈值，可以更好地处理文本框的边界问题。
* 文书特征检测中，我们发现具有高度重叠的指纹与签名，签名的召回率较低，于是单独对两个特征进行建模，然后针对同一个测试集分别测试指纹与签名的指标，发现签名会有5% 的提升，于是猜测可能是模型用一个head对两个高度重合的特征建模的拟合能力不够强
  * 对比前后两组实验，除去backbone部分，最大的区别就是，前者使用了一个detetion head建模多个目标，而后者则是使用多个detection head分别建模一个目标，因此我们共享backbone部分，使用多个detection head进行了新的对比试验，试验从结果来看，签名的识别率从 87%提升到90%
* 身份证识别，在身份证结构化提取的过程中，发现会抽取到背景文字，因此，我们增加了身份证框检测模块，降低背景的干扰
* 对于生僻字或者是长尾字符，我们采用数据增强的方法，结合不同包含该字符的语料，生成相应的图片数据

